
#Hugging Face Transformers library

# Hugging Face Transformers library is a powerful Python library that provides APIs 
# and tools to easily download, manipulate, and run thousands of pre-trained, 
# open-source AI models for various tasks across natural language processing,
# computer vision, audio, and multimodal learning. 

#Working with API - Hugging Face
Login into your account:
https://huggingface.co/

click on : https://huggingface.co/settings/tokens
or Profile > settings > Access Tokens
> Generate an apikey by clicking on 'create new token'
name: HUGGINGFACEHUB_API_TOKEN
type: write

Create a folder : Sample_Codes
> cd Sample_Codes
--Create a file here as .env
--update in .env
HUGGINGFACEHUB_API_TOKEN=""

--Now create virtual environment
> python -m venv venv
> cd venv/Scripts
> activate
> (venv) E:\Sample_Codes\venv>pip install -U langchain-huggingface
> (venv) E:\Sample_Codes\venv>pip install dotenv
> (venv) E:\Sample_Codes\venv>pip install langchain langchain-community langchain-core
> (venv) E:\Sample_Codes\venv>pip list

#Refer: 1-hf_api.py to see how to load .env containing your token and using llms from HF
#Refer: 2.0-langchain_v1.py to load token directly and use llms from HF

> (venv) E:\Sample_Codes\venv>pip install hf_xet
> (venv) E:\Sample_Codes\venv>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
> (venv) E:\Sample_Codes\venv>pip install transformers
--reinstall transformers to be safe (if needed: pip install --upgrade transformers)
> (venv) E:\Sample_Codes\venv>pip install --upgrade transformers

#Refer: 2.1-transfpipe.py to load models from transformers library
---------------------------------------------------------------------------
#Working with transformers library & langchain
#Refer: 2.2-langchain.py to use llms and langchain

#Refer: 2.3-langchain.py for usage of kwargs for llms 
--may show warning such as below
The class `LLMChain` was deprecated in 
LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence

#Woring with more than 1 model
The LLMChain in LangChain is designed to work with one model at a time, 
as it requires a single llm instance when initialized
llm_chain = LLMChain(prompt=prompt, llm=llm)

This means it cannot natively switch between multiple models within the same chain.
If you want to use different models dynamically:
#Refer: 2.4-langchain.py

#Use a Router Chain (Advanced)
If you need automatic model selection based on the input, LangChain provides 
Router Chains that intelligently choose which model 
to use based on the question.
