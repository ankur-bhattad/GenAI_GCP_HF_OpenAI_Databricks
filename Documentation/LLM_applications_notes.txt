Prompt engineering
--prompts
  --input(template,structure,generation settings,other settings), output
  --roles
  --examples(one shot, few shot)
  --parameters (input)
  --keywords (search web, use a real-time tool) : usage of tools
  --indication of techniques
choice of model: llm (what version) (what kind of tasks)
                 Pre-trained model and using it as it is
                 Pre-trained model and refining it using a additional layer
                 Creating your own model and its components
how do you invoke:
        Q&A - api interaction
        Chat model
Agentic implementation - agentic applications
                         decision, integrate/talk to external sources/internal comm
Usage of different frameworks
         langchain
         langraph
         autogen

Responses generated
--avoid hallucination
   --no bias magnification
   --accurate/appropriate(usage of negative prompts along with positive prompts)
   --in context/as per instructions
   --proper format

Validations
     --validate responses
     --benchmark evaluations

import..
llm = model
pos_prompt = 'generate an image of forest'
neg_prompt = 'blury, dark, unclear'
model.response(pos_prompt,neg_prompt)




        
  