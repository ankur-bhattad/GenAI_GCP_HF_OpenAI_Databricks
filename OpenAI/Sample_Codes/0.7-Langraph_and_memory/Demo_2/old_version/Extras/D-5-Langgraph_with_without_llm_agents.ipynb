{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "n4g7XdKKlOaLIdAyaiGiJIfN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4g7XdKKlOaLIdAyaiGiJIfN",
        "outputId": "1e576af4-9050-496f-9394-459292613d4d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.76)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "rItwtPeEsN7q",
      "metadata": {
        "id": "rItwtPeEsN7q"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "#from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "#from langchain.utilities import PythonREPL\n",
        "from langchain_experimental.utilities import PythonREPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cqdl24BtstR8",
      "metadata": {
        "id": "Cqdl24BtstR8"
      },
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    azure_deployment=\"gpt-4.1-mini\",         # deployment name from Azure portal\n",
        "    azure_endpoint=\"https://singhlkaay-7416-resource.cognitiveservices.azure.com/\",           # your endpoint\n",
        "    api_version=\"2023-12-01-preview\",\n",
        "    api_key=\"mykey\",\n",
        "    temperature=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "TVhfAAGws294",
      "metadata": {
        "id": "TVhfAAGws294"
      },
      "outputs": [],
      "source": [
        "# Shared state\n",
        "class State(dict): pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "-qKpmDBgtAVm",
      "metadata": {
        "id": "-qKpmDBgtAVm"
      },
      "outputs": [],
      "source": [
        "# Nodes\n",
        "def classify_problem(state: State):\n",
        "    \"\"\"Optionally LLM could be used to decide whether math is small or large.\"\"\"\n",
        "    expr = state[\"query\"]\n",
        "    # crude heuristic: look for big exponents\n",
        "    if \"**\" in expr and int(expr.split(\"**\")[1].split()[0]) > 20:\n",
        "        state[\"route\"] = \"tool\"\n",
        "    else:\n",
        "        state[\"route\"] = \"direct\"\n",
        "    return state\n",
        "\n",
        "def direct_compute(state: State):\n",
        "    \"\"\"Handle small computations directly.\"\"\"\n",
        "    # Example: just hardcode simple eval here\n",
        "    state[\"answer\"] = eval(state[\"query\"].replace(\"log\", \"(__import__('math').log)\"))\n",
        "    return state\n",
        "\n",
        "def python_tool_compute(state: State):\n",
        "    \"\"\"Use Python REPL for large computations.\"\"\"\n",
        "    repl = PythonREPL()\n",
        "    result = repl.run(state[\"query\"].replace(\"log\", \"(__import__('math').log)\"))\n",
        "    state[\"answer\"] = result\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "DsNQQAz6tQji",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsNQQAz6tQji",
        "outputId": "a01578b8-28b0-4f9a-bb45-524536b1cc73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a41087745d0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build graph\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"classify\", classify_problem)\n",
        "graph.add_node(\"direct\", direct_compute)\n",
        "graph.add_node(\"tool\", python_tool_compute)\n",
        "#graph.add_node(\"extra\",myown_func)\n",
        "\n",
        "graph.set_entry_point(\"classify\")\n",
        "graph.add_conditional_edges(\"classify\", lambda s: s[\"route\"], {\"direct\": \"direct\", \"tool\": \"tool\"})\n",
        "graph.add_edge(\"direct\", END)\n",
        "graph.add_edge(\"tool\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "63t6kk-bwaGw",
      "metadata": {
        "id": "63t6kk-bwaGw"
      },
      "outputs": [],
      "source": [
        "#query = {\"query\": \"10000 * 12**100 - 12 + log(10**1000)\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bQ2ScSPbvBC0",
      "metadata": {
        "id": "bQ2ScSPbvBC0"
      },
      "outputs": [],
      "source": [
        "# Run\n",
        "app = graph.compile()\n",
        "#state = app.invoke(query[\"query\"])\n",
        "#print(\"Final Answer:\", state[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Z5aAawywTH9",
      "metadata": {
        "id": "6Z5aAawywTH9"
      },
      "outputs": [],
      "source": [
        "#Using LLM and validation with user input\n",
        "def classify_with_llm(state: State):\n",
        "    \"\"\"Use LLM to decide whether problem is SMALL or LARGE.\"\"\"\n",
        "    expr = state[\"query\"]\n",
        "    prompt = f\"\"\"\n",
        "    You are a reasoning assistant.\n",
        "    Task: Decide if this math problem should be solved directly or with a calculator.\n",
        "    If it has large exponents (like **50 or higher), say \"LARGE\".\n",
        "    Otherwise, say \"SMALL\".\n",
        "\n",
        "    Problem: {expr}\n",
        "    Answer only with SMALL or LARGE.\n",
        "    \"\"\"\n",
        "    decision = llm.invoke(prompt).content.strip()\n",
        "    state[\"llm_decision\"] = decision\n",
        "    return state\n",
        "\n",
        "def user_validation(state: State):\n",
        "    \"\"\"Ask user to validate the LLM's choice before execution.\"\"\"\n",
        "    decision = state[\"llm_decision\"]\n",
        "    print(f\"ðŸ¤– LLM thinks this problem is: {decision}\")\n",
        "    user_input = input(\"Do you agree? (yes/no): \").strip().lower()\n",
        "\n",
        "    if user_input == \"no\":\n",
        "        # Let user override\n",
        "        override = input(\"Enter your choice (SMALL/LARGE): \").strip().upper()\n",
        "        state[\"route\"] = override\n",
        "    else:\n",
        "        state[\"route\"] = decision\n",
        "    return state\n",
        "\n",
        "def direct_compute(state: State):\n",
        "    \"\"\"Handle small computations directly.\"\"\"\n",
        "    state[\"answer\"] = eval(state[\"query\"].replace(\"log\", \"(__import__('math').log)\"))\n",
        "    return state\n",
        "\n",
        "def python_tool_compute(state: State):\n",
        "    \"\"\"Use Python REPL for large computations.\"\"\"\n",
        "    repl = PythonREPL()\n",
        "    result = repl.run(state[\"query\"].replace(\"log\", \"(__import__('math').log)\"))\n",
        "    state[\"answer\"] = result\n",
        "    return state\n",
        "\n",
        "# --- Build the graph ---\n",
        "graph = StateGraph(State)\n",
        "\n",
        "graph.add_node(\"classify\", classify_with_llm)\n",
        "graph.add_node(\"validate\", user_validation)\n",
        "graph.add_node(\"direct\", direct_compute)\n",
        "graph.add_node(\"tool\", python_tool_compute)\n",
        "\n",
        "graph.set_entry_point(\"classify\")\n",
        "graph.add_edge(\"classify\", \"validate\")\n",
        "\n",
        "# Conditional edge after validation\n",
        "graph.add_conditional_edges(\n",
        "    \"validate\",\n",
        "    lambda s: s[\"route\"],\n",
        "    {\"SMALL\": \"direct\", \"LARGE\": \"tool\"}\n",
        ")\n",
        "\n",
        "graph.add_edge(\"direct\", END)\n",
        "graph.add_edge(\"tool\", END)\n",
        "\n",
        "# --- Run it ---\n",
        "app = graph.compile()\n",
        "\n",
        "state = app.invoke({\"query\": \"10000 * 12**100 - 12 + log(10**1000)\"})\n",
        "print(\"Final Answer:\", state[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cjnuIGVSxNFN",
      "metadata": {
        "id": "cjnuIGVSxNFN"
      },
      "outputs": [],
      "source": [
        "#implementing agents, with langraph and call to llm, user validation of llm response\n",
        "# Tool: Python calculator\n",
        "python_tool = Tool(\n",
        "    name=\"Python Calculator\",\n",
        "    func=PythonREPL().run,\n",
        "    description=\"Execute Python for large math computations.\"\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# Agent 1: Classifier Agent\n",
        "classifier_prompt = \"\"\"\n",
        "You are a classification agent.\n",
        "Task: Look at the given math expression and decide if it's SMALL or LARGE.\n",
        "Rule: If exponent >= 50, it's LARGE. Otherwise, it's SMALL.\n",
        "Answer ONLY 'SMALL' or 'LARGE'.\n",
        "\"\"\"\n",
        "classifier_agent = initialize_agent([], llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "def classify_with_agent(state: State):\n",
        "    expr = state[\"query\"]\n",
        "    response = classifier_agent.run(classifier_prompt + f\"\\nExpression: {expr}\")\n",
        "    state[\"llm_decision\"] = response.strip().upper()\n",
        "    return state\n",
        "\n",
        "# User validation node\n",
        "def user_validation(state: State):\n",
        "    decision = state[\"llm_decision\"]\n",
        "    print(f\" Classifier Agent thinks this problem is: {decision}\")\n",
        "    user_input = input(\"Do you agree? (yes/no): \").strip().lower()\n",
        "\n",
        "    if user_input == \"no\":\n",
        "        override = input(\"Enter your choice (SMALL/LARGE): \").strip().upper()\n",
        "        state[\"route\"] = override\n",
        "    else:\n",
        "        state[\"route\"] = decision\n",
        "    return state\n",
        "\n",
        "# Agent 2: Math Agent (can use tool)\n",
        "math_agent = initialize_agent([python_tool], llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "def solve_with_agent(state: State):\n",
        "    expr = state[\"query\"]\n",
        "\n",
        "    if state[\"route\"] == \"SMALL\":\n",
        "        # Direct computation (no tool)\n",
        "        state[\"answer\"] = eval(expr.replace(\"log\", \"(__import__('math').log)\"))\n",
        "    else:\n",
        "        # Delegate to math agent with tool\n",
        "        result = math_agent.run(expr.replace(\"log\", \"(__import__('math').log)\"))\n",
        "        state[\"answer\"] = result\n",
        "\n",
        "    return state\n",
        "\n",
        "# --- Build LangGraph workflow ---\n",
        "graph = StateGraph(State)\n",
        "\n",
        "graph.add_node(\"classify\", classify_with_agent)\n",
        "graph.add_node(\"validate\", user_validation)\n",
        "graph.add_node(\"solve\", solve_with_agent)\n",
        "\n",
        "graph.set_entry_point(\"classify\")\n",
        "graph.add_edge(\"classify\", \"validate\")\n",
        "graph.add_edge(\"validate\", \"solve\")\n",
        "graph.add_edge(\"solve\", END)\n",
        "\n",
        "# --- Run ---\n",
        "app = graph.compile()\n",
        "\n",
        "state = app.invoke({\"query\": \"10000 * 12**100 - 12 + log(10**1000)\"})\n",
        "print(\"Final Answer:\", state[\"answer\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "kuma24aj24 (Sep 12, 2025, 4:08:39â€¯AM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
