{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w4cZkCu8Z-vD",
      "metadata": {
        "id": "w4cZkCu8Z-vD"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain langchain-core langchain_community langchain_openai\n",
        "#Using langchain for templates\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cHFJLbLWFl1",
      "metadata": {
        "id": "4cHFJLbLWFl1"
      },
      "outputs": [],
      "source": [
        "#Using OpenAI and gpt model\n",
        "#Note** If using gpt model and AzureOpenAI or AzureChatOpenAI (refer: 'Working_with_AzureOpenAI' folder)\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# Initialize client once\n",
        "client = AzureOpenAI(\n",
        "    api_key=\"your api key\",\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    azure_endpoint=\"https://singhalkajay-7416-resource.cognitiveservices.azure.com/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "grSdJUUXWT7H",
      "metadata": {
        "id": "grSdJUUXWT7H"
      },
      "outputs": [],
      "source": [
        "#Creating function\n",
        "def get_completion(prompt, deployment_name=\"gpt-4.1-mini\"):\n",
        "    \"\"\"\n",
        "    Get a chat completion from Azure OpenAI.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): User input prompt.\n",
        "        deployment_name (str): The deployment name you gave your model in Azure portal.\n",
        "\n",
        "    Returns:\n",
        "        dict: Full response object, or error dict.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=deployment_name,    # <-- This is the \"deployment name\" not the raw model name\n",
        "            messages=messages,\n",
        "            temperature=0.1,\n",
        "            top_p=0.8,\n",
        "            max_tokens=512\n",
        "        )\n",
        "\n",
        "        #return response.model_dump()  # Return the full response as dict\n",
        "        # Extract just the assistant's reply\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XEfncM0MarDG",
      "metadata": {
        "id": "XEfncM0MarDG"
      },
      "outputs": [],
      "source": [
        "response = get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U89xZUgea_O6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "U89xZUgea_O6",
        "outputId": "7932c623-3439-44b5-aa15-c2673ebb2f47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"The Great Gatsby,\" written by F. Scott Fitzgerald, is a classic novel set in the Jazz Age of the 1920s. It tells the story of Jay Gatsby, a wealthy and mysterious man known for his lavish parties, and his unrelenting love for Daisy Buchanan. Narrated by Nick Carraway, the novel explores themes of ambition, love, wealth, and the American Dream, ultimately revealing the moral decay beneath the glittering surface of high society.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4utCFeQAWuBF",
      "metadata": {
        "id": "4utCFeQAWuBF"
      },
      "outputs": [],
      "source": [
        "#Using other models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rFPKfkl6bB1W",
      "metadata": {
        "id": "rFPKfkl6bB1W"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H9RTg_q4rlzp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9RTg_q4rlzp",
        "outputId": "616e8ec2-8388-4483-af9a-3e5da970690b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: protobuf\n",
            "Version: 3.20.3\n",
            "Summary: Protocol Buffers\n",
            "Home-page: https://developers.google.com/protocol-buffers/\n",
            "Author: \n",
            "Author-email: \n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: \n",
            "Required-by: google-ai-generativelanguage, google-api-core, google-cloud-aiplatform, google-cloud-appengine-logging, google-cloud-audit-log, google-cloud-bigquery-connection, google-cloud-bigquery-storage, google-cloud-bigtable, google-cloud-dataproc, google-cloud-datastore, google-cloud-discoveryengine, google-cloud-firestore, google-cloud-functions, google-cloud-language, google-cloud-logging, google-cloud-monitoring, google-cloud-resource-manager, google-cloud-secret-manager, google-cloud-spanner, google-cloud-speech, google-cloud-trace, google-cloud-translate, google-colabsqlviz, google-generativeai, googleapis-common-protos, grpc-google-iam-v1, grpcio-status, kaggle, opentelemetry-proto, orbax-checkpoint, proto-plus, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-metadata, wandb, ydf, yfinance\n"
          ]
        }
      ],
      "source": [
        "!pip show protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I0Lo4BGgrqtd",
      "metadata": {
        "id": "I0Lo4BGgrqtd"
      },
      "outputs": [],
      "source": [
        "#downgrade protobuf to avoid warnings,if needed\n",
        "#!pip install --upgrade protobuf==4.25.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iDwutMJKr5AJ",
      "metadata": {
        "id": "iDwutMJKr5AJ"
      },
      "outputs": [],
      "source": [
        "#restart session,if above step done\n",
        "#from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61VuGAEXssEW",
      "metadata": {
        "id": "61VuGAEXssEW"
      },
      "outputs": [],
      "source": [
        "#Note**Access to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must have access to it and be\n",
        "#authenticated to access it. If yes, then we can use the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g9-SQxS7s3Bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "g9-SQxS7s3Bb",
        "outputId": "001bf0e5-0579-47ac-9a2d-2a55a4808292"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ngenerator = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.1\")\\n\\n\\ndef get_completion(prompt):\\n    # For instruction-tuned models, prepend with an instruction-style format\\n    instruction = f\"<s>[INST] {prompt} [/INST]\"\\n    response = generator(instruction, max_new_tokens=100, do_sample=False)\\n    return response[0][\"generated_text\"].split(\"[/INST]\")[-1].strip()\\n\\nprint(get_completion(\"What is defi in context of crypto world?\"))\\n'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#Note ** this will download large tensors,configs etc.. for this model, thus to run remove \"\"\" \"\"\" & then run\n",
        "\"\"\"\n",
        "generator = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "\n",
        "\n",
        "def get_completion(prompt):\n",
        "    # For instruction-tuned models, prepend with an instruction-style format\n",
        "    instruction = f\"<s>[INST] {prompt} [/INST]\"\n",
        "    response = generator(instruction, max_new_tokens=100, do_sample=False)\n",
        "    return response[0][\"generated_text\"].split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "print(get_completion(\"What is defi in context of crypto world?\"))\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YhP8jnZgtC3C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "YhP8jnZgtC3C",
        "outputId": "143366ba-6f63-47a2-882f-b830d3b2c370"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Load a text-generation pipeline with an instruction-tuned model\\ngenerator = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\")\\n\\ndef get_completion(prompt):\\n    # For instruction-tuned models, prepend with an instruction-style format\\n    instruction = f\"<s>[INST] {prompt} [/INST]\"\\n    response = generator(instruction, max_new_tokens=100, do_sample=False)\\n    return response[0][\"generated_text\"].split(\"[/INST]\")[-1].strip()\\n\\nprint(get_completion(\"What is defi in context of crypto world?\"))\\n'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##using heavier model\n",
        "#Note ** this will download large tensors,configs etc.. for this model, thus to run remove \"\"\" \"\"\" & then run\n",
        "\"\"\"\n",
        "# Load a text-generation pipeline with an instruction-tuned model\n",
        "generator = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\")\n",
        "\n",
        "def get_completion(prompt):\n",
        "    # For instruction-tuned models, prepend with an instruction-style format\n",
        "    instruction = f\"<s>[INST] {prompt} [/INST]\"\n",
        "    response = generator(instruction, max_new_tokens=100, do_sample=False)\n",
        "    return response[0][\"generated_text\"].split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "print(get_completion(\"What is defi in context of crypto world?\"))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSlyD4a5tMsx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSlyD4a5tMsx",
        "outputId": "4505c12b-db58-420d-9347-b82936ff7edd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "crypto currency\n"
          ]
        }
      ],
      "source": [
        "#Using smaller model\n",
        "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "def get_completion(prompt):\n",
        "    # For instruction-tuned models, prepend with an instruction-style format\n",
        "    #instruction = f\"<s>[INST] {prompt} [/INST]\"\n",
        "    response = generator(prompt,max_new_tokens=100, do_sample=False)\n",
        "    return (response[0][\"generated_text\"].strip())\n",
        "\n",
        "print(get_completion(\"What is a DEFI in context of crypto world\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tThuPF9Bb7mz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "tThuPF9Bb7mz",
        "outputId": "d8297751-1299-423f-a5fd-b788659f8f9d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ngenerator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\\ndef get_completion(prompt):\\n    # For instruction-tuned models, prepend with an instruction-style format\\n    instruction = f\"<s>[INST] {prompt} [/INST]\"\\n    response = generator(instruction, max_new_tokens=100, do_sample=False)\\n    return response[0][\"generated_text\"].split(\"[/INST]\")[-1].strip()\\n\\nprint(get_completion(\"What is defi in context of crypto world?\"))\\n'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Using different variant i.e larger model, to run remove \"\"\" \"\"\"\n",
        "\"\"\"\n",
        "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
        "def get_completion(prompt):\n",
        "    # For instruction-tuned models, prepend with an instruction-style format\n",
        "    instruction = f\"<s>[INST] {prompt} [/INST]\"\n",
        "    response = generator(instruction, max_new_tokens=100, do_sample=False)\n",
        "    return response[0][\"generated_text\"].split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "print(get_completion(\"What is defi in context of crypto world?\"))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zH-ltiWabmFG",
      "metadata": {
        "id": "zH-ltiWabmFG"
      },
      "outputs": [],
      "source": [
        "templatee = \" Please write a {length} review,of the book {book_title}. \"\n",
        "input_variabless = [ \"length\", \"book_title\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_HGV2537bpTx",
      "metadata": {
        "id": "_HGV2537bpTx"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=input_variabless,\n",
        "    template=templatee\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9DAcLOzbsEr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9DAcLOzbsEr",
        "outputId": "1b0436ce-b84e-484c-d6b3-7b3960723773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Please write a short review,of the book  House Of Dragon. \n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = prompt.format(length = \"short\", book_title = \" House Of Dragon\")\n",
        "\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BwQK6X1EbvkS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwQK6X1EbvkS",
        "outputId": "4d1bd92c-fd37-4556-9695-4d7434445570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI Response:\n",
            "<class 'str'>\n",
            "House of Dragon is a well-written, well-acted, and well-written fantasy novel.\n"
          ]
        }
      ],
      "source": [
        "response = get_completion(formatted_prompt)\n",
        "print(\"AI Response:\")\n",
        "print(type(response))\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A4vAy34ycA3m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "A4vAy34ycA3m",
        "outputId": "31e07ec1-795f-4eac-94ca-f5ecd2a2e2f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nresponse = get_completion(formatted_prompt)\\nprint(\"AI Response:\")\\nprint(type(response))\\nprint(response.keys())\\n\\nresponse[\\'choices\\'][0][\\'message\\'][\\'content\\']'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#If using get_completion() based on gpt model as defined above, then we can\n",
        "\"\"\"\n",
        "response = get_completion(formatted_prompt)\n",
        "print(\"AI Response:\")\n",
        "print(type(response))\n",
        "print(response.keys())\n",
        "\n",
        "response['choices'][0]['message']['content']\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTEmVTbtcaz_",
      "metadata": {
        "id": "FTEmVTbtcaz_"
      },
      "outputs": [],
      "source": [
        "#Jinja Template example\n",
        "jinja2_template = \"Give me an {{ adjective }} fact about {{ topic }}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hs4lWHCwcd36",
      "metadata": {
        "id": "hs4lWHCwcd36"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate.from_template(jinja2_template, template_format = \"jinja2\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tjoUtBSAcg1F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjoUtBSAcg1F",
        "outputId": "8955f475-e3ee-4bea-9813-e05103ad5956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give me an interesting fact about space exploration\n"
          ]
        }
      ],
      "source": [
        "user_question = prompt.format(adjective=\"interesting\", topic=\"space exploration\")\n",
        "print(user_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cmNOjToMcksj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmNOjToMcksj",
        "outputId": "93f5f499-af37-4cc9-fa66-46b5b00c71b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI Response:\n",
            "Space exploration is a form of exploration of the universe.\n"
          ]
        }
      ],
      "source": [
        "response = get_completion(user_question)\n",
        "print(\"AI Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H4St5tIJcvxG",
      "metadata": {
        "id": "H4St5tIJcvxG"
      },
      "outputs": [],
      "source": [
        "#Using f-string (example)\n",
        "fstring_template = \"Here is a brief summary for the book titled '{book_title}':\"\n",
        "\n",
        "book_title = \"The Great Gatsby\"\n",
        "\n",
        "prompt = fstring_template.format(book_title=book_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5hTvPScdc1Sr",
      "metadata": {
        "id": "5hTvPScdc1Sr"
      },
      "outputs": [],
      "source": [
        "#Testing a dummy function\n",
        "def get_book_summary(prompt):\n",
        "\n",
        "    return \"It's a novel about love, wealth, and aspiration, set in the Roaring '20s.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dL3AVzJIc4we",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL3AVzJIc4we",
        "outputId": "082e3c13-4bf4-4100-9dee-bc52eeefa2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It's a novel about love, wealth, and aspiration, set in the Roaring '20s.\n"
          ]
        }
      ],
      "source": [
        "summary = get_book_summary(prompt)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3wyAldXCc7FD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wyAldXCc7FD",
        "outputId": "ee06ccbf-afb3-4eaa-f9b9-ae126fc716f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI Response:\n",
            "'The Great Gatsby' is a book about a young man's journey from a small town to a big city.\n"
          ]
        }
      ],
      "source": [
        "#Using function that invokes the LLM\n",
        "response = get_completion(prompt)\n",
        "print(\"AI Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "agn5QcgSdKdj",
      "metadata": {
        "id": "agn5QcgSdKdj"
      },
      "outputs": [],
      "source": [
        "# Example where string prompt template would not work\n",
        "# Define the prompt template\n",
        "\n",
        "jinja2_template = \"\"\"\n",
        "\n",
        "Dear {{ name }},\n",
        "{% if age < 18 %}\n",
        "You are invited to our kids' event with activities such as face painting, bouncy castles, and clown shows.\n",
        "{% elif age < 65 %}\n",
        "You are invited to our adult event with activities like live music, wine tasting, and art workshops.\n",
        "{% else %}\n",
        "You are invited to our senior event with activities including book clubs, chess tournaments, and tea dances.\n",
        "{% endif %}\n",
        "Sincerely,\n",
        "Event Organizer\n",
        "\n",
        "Write the mail in 200 words\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u7f6J5vIdQqU",
      "metadata": {
        "id": "u7f6J5vIdQqU"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
        "\n",
        "# Format the prompt with specific values for 'action', 'group', and 'time_period'\n",
        "argument_prompt = prompt.format(name=\"John Doe\", age=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pmi2AVlEdT3B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmi2AVlEdT3B",
        "outputId": "5ed5e618-2cf0-4165-c9a7-c788d4b3b321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI Response:\n",
            "Dear John Doe, You are invited to our kids' event with activities such as face painting, bouncy castles, and clown shows. Sincerely, Event Organizer\n"
          ]
        }
      ],
      "source": [
        "response = get_completion(argument_prompt)\n",
        "print(\"AI Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810t5vvydiXP",
      "metadata": {
        "id": "810t5vvydiXP"
      },
      "outputs": [],
      "source": [
        "#Using Langchain templates & chat mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AyTBNlvNdlIS",
      "metadata": {
        "id": "AyTBNlvNdlIS"
      },
      "outputs": [],
      "source": [
        "simple_prompt = \"The {subject} is strong in this one.\"\n",
        "human_prompt = \"Summarize our conversation so far in {word_count} words.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CceHGGrJdnuQ",
      "metadata": {
        "id": "CceHGGrJdnuQ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aD80fkXJeVkP",
      "metadata": {
        "id": "aD80fkXJeVkP"
      },
      "outputs": [],
      "source": [
        "simple_message_template = HumanMessagePromptTemplate.from_template(simple_prompt)\n",
        "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    MessagesPlaceholder(variable_name=\"conversation\"),\n",
        "    simple_message_template,\n",
        "    human_message_template\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4EMO8L7Gd8TB",
      "metadata": {
        "id": "4EMO8L7Gd8TB"
      },
      "outputs": [],
      "source": [
        "human_message = HumanMessage(content=\"What's the best way to learn a new language?\")\n",
        "ai_message = AIMessage(content=\"\"\"\\\n",
        "1. Immerse yourself in the language: Try to use the language in your daily life as much as possible.\n",
        "2. Practice regularly: Consistency is key when learning a new language.\n",
        "3. Use language learning apps: There are many apps that can help you learn a new language in a fun and engaging way.\\\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C26TL-d3ecxv",
      "metadata": {
        "id": "C26TL-d3ecxv"
      },
      "outputs": [],
      "source": [
        "conversation = chat_prompt.format_prompt(\n",
        "    conversation=[human_message, ai_message],\n",
        "    subject=\"Force\",\n",
        "    word_count=\"10\"\n",
        ").to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0yBpfaTCefGE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yBpfaTCefGE",
        "outputId": "151625c5-c910-4d19-d284-4a212da70128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[HumanMessage(content=\"What's the best way to learn a new language?\", additional_kwargs={}, response_metadata={}), AIMessage(content='1. Immerse yourself in the language: Try to use the language in your daily life as much as possible.\\n2. Practice regularly: Consistency is key when learning a new language.\\n3. Use language learning apps: There are many apps that can help you learn a new language in a fun and engaging way.', additional_kwargs={}, response_metadata={}), HumanMessage(content='The Force is strong in this one.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Summarize our conversation so far in 10 words.', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "print(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FI2z-SWVemTr",
      "metadata": {
        "id": "FI2z-SWVemTr"
      },
      "outputs": [],
      "source": [
        "simple_prompt = \"The {subject} is fascinating to study.\"\n",
        "human_prompt = \"Summarize our conversation so far in {word_count} words.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tb5BiHPseo9t",
      "metadata": {
        "id": "tb5BiHPseo9t"
      },
      "outputs": [],
      "source": [
        "human_message = HumanMessage(content=\"What's happens inside a black hole\")\n",
        "ai_message = AIMessage(content=\"\"\"\\\n",
        "1. Inside black hole gariivty is zero way.\\\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cowplr9CerZS",
      "metadata": {
        "id": "cowplr9CerZS"
      },
      "outputs": [],
      "source": [
        "conversation = chat_prompt.format_prompt(\n",
        "    conversation=[human_message, ai_message],\n",
        "    subject=\"Black Hole\",\n",
        "    word_count=\"10\"\n",
        ").to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J9pkARPAeuM-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9pkARPAeuM-",
        "outputId": "1869e6a2-ebb4-4a29-f2d6-9eaaba847386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formatted Prompt:\n",
            "[HumanMessage(content=\"What's happens inside a black hole\", additional_kwargs={}, response_metadata={}), AIMessage(content='1. Inside black hole gariivty is zero way.', additional_kwargs={}, response_metadata={}), HumanMessage(content='The Black Hole is strong in this one.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Summarize our conversation so far in 10 words.', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "prompt_string = conversation\n",
        "print(\"Formatted Prompt:\")\n",
        "print(prompt_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sMkcZJdeexjy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMkcZJdeexjy",
        "outputId": "82f1b4ef-a923-457c-9984-0b9c83ced838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "print(type(prompt_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5GorO6yye69i",
      "metadata": {
        "id": "5GorO6yye69i"
      },
      "outputs": [],
      "source": [
        "#To be fixed in format\n",
        "#response = get_completion(prompt_string)\n",
        "#print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S4GQHysnfPz_",
      "metadata": {
        "id": "S4GQHysnfPz_"
      },
      "outputs": [],
      "source": [
        "#Using Langchain templates & styles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XKl1hRBidWOi",
      "metadata": {
        "id": "XKl1hRBidWOi"
      },
      "outputs": [],
      "source": [
        "#Using style\n",
        "#Modify parameters like **customer_style** and **customer_email**\n",
        "#to influence the tone and formality of the generated responses.\n",
        "\n",
        "template_string = \"\"\"Translate the text that is delimited by triple backticks into a style\n",
        "that is {style}. text: ```{text}```\"\"\"\n",
        "\n",
        "# Style and email input\n",
        "customer_style = \"American English in a casual tone\"\n",
        "customer_email = \"\"\"\n",
        "I'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZFn3RUBrewkI",
      "metadata": {
        "id": "ZFn3RUBrewkI"
      },
      "outputs": [],
      "source": [
        "prompt = template_string.format(style=customer_style, text=customer_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7YYMKLJDe5NW",
      "metadata": {
        "id": "7YYMKLJDe5NW"
      },
      "outputs": [],
      "source": [
        "instruction_prompt = f\"<s>[INST] {prompt} [/INST]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3kwf7KxIfC1Q",
      "metadata": {
        "id": "3kwf7KxIfC1Q"
      },
      "outputs": [],
      "source": [
        "#Using generator based on google/flan-t5-base\n",
        "response = generator(instruction_prompt, max_new_tokens=150, do_sample=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JiJaulYkfI6j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiJaulYkfI6j",
        "outputId": "d723466c-ae2c-4d7d-d847-43b56d3512b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': \" I'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!  [/INST]\"}]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HEuciaAUf5EH",
      "metadata": {
        "id": "HEuciaAUf5EH"
      },
      "outputs": [],
      "source": [
        "generated_text = response[0]['generated_text'].split(\"[/INST]\")[-1].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dTjSkY88gsP2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTjSkY88gsP2",
        "outputId": "ad21df40-5733-4b0c-c589-0dc0f9c89a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'generated_text': \" I'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!  [/INST]\"}\n"
          ]
        }
      ],
      "source": [
        "print(response[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "likfR2Jufx6L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "likfR2Jufx6L",
        "outputId": "d50dd67d-a196-4ceb-d92e-5a4592ca1647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': \" I'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!\"}]\n"
          ]
        }
      ],
      "source": [
        "template_string = \"\"\"Translate the text that is delimited by triple backticks into a style that is {style}.\n",
        "text: ```{text}```\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    style=\"Scottish English in a professional tone\",\n",
        "    text=\"I'm super excited about the new gaming console & new game!\"\n",
        ")\n",
        "\n",
        "#Using generator based on google/flan-t5-base\n",
        "response = generator(prompt,max_new_tokens=150, do_sample=False)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TQD5F4wKlgzq",
      "metadata": {
        "id": "TQD5F4wKlgzq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "1.3-Formatting_n_Instructions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
