{
  "cells": [
    {
      "cell_type": "code",
      "id": "jxWGPpg0UQLhmezVKsgLGj8n",
      "metadata": {
        "tags": [],
        "id": "jxWGPpg0UQLhmezVKsgLGj8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c2a7d9-12b7-4dd1-ba71-ed944ff6ff78"
      },
      "source": [
        "!pip install requests python-dotenv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "load_dotenv(\"/content/.env\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zotQGcuaO_py",
        "outputId": "ddf2e19b-4a0f-40a4-836f-8e0ab46b3231"
      },
      "id": "zotQGcuaO_py",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_key=API_KEY,\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    deployment_name=\"gpt-4.1\",\n",
        "    temperature=0,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "JKB1hWiVPT6b",
        "outputId": "163187eb-10cb-40cc-dcc6-d4e9518183d9"
      },
      "id": "JKB1hWiVPT6b",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AZURE_OPENAI_ENDPOINT' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3041411650.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m llm = AzureChatOpenAI(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mazure_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAZURE_OPENAI_ENDPOINT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAPI_KEY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mapi_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2024-12-01-preview\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdeployment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4.1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AZURE_OPENAI_ENDPOINT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define web search\n",
        "@tool\n",
        "def web_search(query: str) -> str:\n",
        "    \"\"\"Search the web for real-time or current information.\"\"\"\n",
        "    url = \"https://serpapi.com/search.json\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"api_key\": SERPAPI_KEY,\n",
        "        \"num\": 5,\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    results = data.get(\"organic_results\", [])\n",
        "    if not results:\n",
        "        return \"No results found.\"\n",
        "\n",
        "    return \"\\n\".join(\n",
        "        r.get(\"snippet\", \"\") for r in results[:3] if r.get(\"snippet\")\n",
        "    )\n"
      ],
      "metadata": {
        "id": "yeQbIrLpRqG0"
      },
      "id": "yeQbIrLpRqG0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessage(\n",
        "        content=(\n",
        "            \"You are an intelligent assistant.\\n\"\n",
        "            \"If the question requires real-time or current information, \"\n",
        "            \"call the appropriate tool.\\n\"\n",
        "            \"Otherwise answer directly.\"\n",
        "        )\n",
        "    ),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "DvRIXsIBR6Ey"
      },
      "id": "DvRIXsIBR6Ey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bind tools to the model\n",
        "llm_with_tools = llm.bind_tools([web_search])"
      ],
      "metadata": {
        "id": "_crgsgquR951"
      },
      "id": "_crgsgquR951",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build runnable chain\n",
        "chain = (\n",
        "    {\"input\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        ")\n"
      ],
      "metadata": {
        "id": "iT5ji7F2SFPc"
      },
      "id": "iT5ji7F2SFPc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Real time tool call\n",
        "response = chain.invoke(\"What is the position of the moon relative to Germany right now?\")\n",
        "response"
      ],
      "metadata": {
        "id": "YaGvZDgNSJ2y"
      },
      "id": "YaGvZDgNSJ2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To execute tool calls automatically\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "def run_with_tools(chain, user_input):\n",
        "    result = chain.invoke(user_input)\n",
        "\n",
        "    if result.tool_calls:\n",
        "        tool_outputs = []\n",
        "        for call in result.tool_calls:\n",
        "            tool_result = web_search.invoke(call[\"args\"])\n",
        "            tool_outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=tool_result,\n",
        "                    tool_call_id=call[\"id\"]\n",
        "                )\n",
        "            )\n",
        "\n",
        "        final = llm.invoke([result, *tool_outputs])\n",
        "        return final.content\n",
        "\n",
        "    return result.content\n"
      ],
      "metadata": {
        "id": "bFep2xpKSWwL"
      },
      "id": "bFep2xpKSWwL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#running tools\n",
        "run_with_tools(\n",
        "    chain,\n",
        "    \"What is the position of the moon relative to Germany right now?\"\n",
        ")"
      ],
      "metadata": {
        "id": "SRloCUH3Sdoj"
      },
      "id": "SRloCUH3Sdoj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_with_tools(\n",
        "    chain,\n",
        "    \"Explain quantum entanglement simply.\"\n",
        ")"
      ],
      "metadata": {
        "id": "XpVduVWIShg0"
      },
      "id": "XpVduVWIShg0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "ak7singhal (Jan 17, 2026, 10:13:51â€¯AM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}