{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "quiNXkxQFzzp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "quiNXkxQFzzp",
        "outputId": "63803b89-5c2b-4fab-929a-a9b4c0291168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers[torch]\n",
            "  Using cached transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "Using cached transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.6\n",
            "    Uninstalling transformers-4.57.6:\n",
            "      Successfully uninstalled transformers-4.57.6\n",
            "Successfully installed transformers-4.57.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "721d1eac2ad046eab522c7d276dab9e1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall \"transformers[torch]\" --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aYaAO8YVGQe9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYaAO8YVGQe9",
        "outputId": "17a9b3c8-8fea-4871-8261-513bce8134f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"accelerate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ooas5oCMGXR_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "ooas5oCMGXR_",
        "outputId": "86c1ea57-ce69-4da7-81b4-2269ac974b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3aeb4ff4c7c94065972e3bf1d1d60217"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install \"numpy<2\" --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "llV2uaNJU2TC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llV2uaNJU2TC",
        "outputId": "55ba06d2-9319-4bf6-983c-0b90f1382f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.7\n",
            "1.2.7\n",
            "1.1.7\n",
            "0.4.1\n",
            "langchain_v 1.2.7\n",
            "langchain_core 1.2.7\n",
            "langchain_community 0.4.1\n",
            "transformers 4.57.6\n",
            "numpy 1.26.4\n"
          ]
        }
      ],
      "source": [
        "#After Restart session\n",
        "import langchain\n",
        "import langchain_core\n",
        "import langchain_openai\n",
        "import langchain_community\n",
        "from importlib.metadata import version\n",
        "import transformers\n",
        "import numpy as np\n",
        "\n",
        "print(version(\"langchain\"))\n",
        "print(version(\"langchain-core\"))\n",
        "print(version(\"langchain-openai\"))\n",
        "print(version(\"langchain-community\"))\n",
        "\n",
        "print(\"langchain_v\",langchain.__version__)\n",
        "print(\"langchain_core\",langchain_core.__version__)\n",
        "print(\"langchain_community\",langchain_community.__version__)\n",
        "print(\"transformers\",transformers.__version__)\n",
        "print(\"numpy\",np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BioKCM6FZyc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BioKCM6FZyc7",
        "outputId": "09165321-870d-458c-f999-f9c0b398b8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (1.2.7)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.6.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.13.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.23.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gyN7O2-eGw8t",
      "metadata": {
        "id": "gyN7O2-eGw8t"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools as lc_load_tools\n",
        "from transformers import pipeline\n",
        "from langchain_core.runnables import RunnableSequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8Aob681jHNeA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Aob681jHNeA",
        "outputId": "fe981c2a-2f9b-4414-dd2d-e9ced69a8dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ],
      "source": [
        "hf_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8T9CGaMkbFCJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T9CGaMkbFCJ",
        "outputId": "c651f66c-ca89-41b0-96b4-8955364adf1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2026.1.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jybGXYcmHvdO",
      "metadata": {
        "id": "jybGXYcmHvdO"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "tools = lc_load_tools([\"llm-math\", \"wikipedia\"], llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E6xxLIj3bWZE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6xxLIj3bWZE",
        "outputId": "1c07bf42-92e1-4aa6-c78e-1358e03b759d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculator -> Useful for when you need to answer questions about math.\n",
            "wikipedia -> A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n"
          ]
        }
      ],
      "source": [
        "for t in tools:\n",
        "    print(t.name, \"->\", t.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ho7DdScQhd2t",
      "metadata": {
        "id": "Ho7DdScQhd2t"
      },
      "outputs": [],
      "source": [
        "def get_tool_by_keyword(keyword):\n",
        "    for t in tools:\n",
        "        if keyword.lower() in t.name.lower():\n",
        "            return t\n",
        "    return None\n",
        "\n",
        "\n",
        "def agent(query: str):\n",
        "    q = query.lower()\n",
        "\n",
        "    # Math routing\n",
        "    if any(x in q for x in [\"*\", \"+\", \"-\", \"/\", \"calculate\", \"math\"]):\n",
        "        tool = get_tool_by_keyword(\"math\") or get_tool_by_keyword(\"calc\")\n",
        "        if tool:\n",
        "            return tool.run(query)\n",
        "\n",
        "    # Wikipedia routing\n",
        "    if any(x in q for x in [\"who\", \"what\", \"where\", \"capital\", \"wiki\"]):\n",
        "        tool = get_tool_by_keyword(\"wiki\")\n",
        "        if tool:\n",
        "            return tool.run(query)\n",
        "\n",
        "    # Fallback\n",
        "    return llm.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3czFxRepiFbW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "3czFxRepiFbW",
        "outputId": "73316788-1573-413f-94c1-56fa1efb305e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Quantum computing (QCC) is a technique that combines the properties of a quantum wave with the properties of a non-resonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the properties of a nonresonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the properties of a nonresonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the properties of a nonresonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the properties of a nonresonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the properties of a nonresonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the properties of a nonresonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the properties of a nonresonant wave. Quantum computing is a technique that combines the properties of a quantum wave with the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "agent(\"What is the capital of France?\")\n",
        "agent(\"Explain quantum computing\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Limited brief response as the model we used is very small\n",
        "agent(\"paris!, thats interesting, any thoughts about paris, give me information related to source etc etc.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tPa18GcRJ3S7",
        "outputId": "2a0dd3eb-66fb-429b-848d-020cfdf02560"
      },
      "id": "tPa18GcRJ3S7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Paris is a city in France.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uG_Fe44Tvr5g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "uG_Fe44Tvr5g",
        "outputId": "e6df8107-b258-4e5f-d1b3-d283b8e2d490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hf_pipeline = pipeline(\\n    \"text-generation\",\\n    model=\"tiiuae/falcon-7b-instruct\",\\n    device=0,\\n    max_new_tokens=256,\\n    temperature=0.0,\\n)\\nllm_model = HuggingFacePipeline(pipeline=hf_pipeline)\\n\\ntools = lc_load_tools([\"llm-math\", \"wikipedia\"], llm=llm_model)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Using a bigger Model & test the same steps as above or continue with base model for now\n",
        "'''hf_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"tiiuae/falcon-7b-instruct\",\n",
        "    device=0,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.0,\n",
        ")\n",
        "llm_model = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "tools = lc_load_tools([\"llm-math\", \"wikipedia\"], llm=llm_model)'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "khJ_r1hjwK5B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "khJ_r1hjwK5B",
        "outputId": "cfc16df8-da55-40d1-8869-4143caf52609"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom langchain.agents import create_react_agent, AgentExecutor\\nfrom langchain import hub\\n\\n# ReAct prompt\\nprompt = hub.pull(\"hwchase17/react\")\\n\\n# Agent\\n#agent = create_react_agent(llm=llm_model, tools=tools, prompt=prompt)\\nagent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\\n# Executor\\nexecutor = AgentExecutor(\\n    agent=agent,\\n    tools=tools,\\n    verbose=True,\\n    handle_parsing_errors=True\\n)\\n\\n#If throws an error then Downgrade all your LangChain packages to a modern, compatible version that includes create_react_agent\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#The steps here might fail as we are using newer version of Langchain which doesnt have\n",
        "#create_react_agent, AgentExecutor etc..Thus commenting out\n",
        "'''\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain import hub\n",
        "\n",
        "# ReAct prompt\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "# Agent\n",
        "#agent = create_react_agent(llm=llm_model, tools=tools, prompt=prompt)\n",
        "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
        "# Executor\n",
        "executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "#If throws an error then Downgrade all your LangChain packages to a modern, compatible version that includes create_react_agent\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WiU90ZuQw9QW",
      "metadata": {
        "id": "WiU90ZuQw9QW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2c8eff74-8e81-4a5e-a839-2c6d6e7c5f50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'question = \"What is the capital of France and what is 17*23?\"\\nresult = executor.invoke({\"input\": question})\\nprint(result[\"output\"])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "'''question = \"What is the capital of France and what is 17*23?\"\n",
        "result = executor.invoke({\"input\": question})\n",
        "print(result[\"output\"])\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NKOg11GyxB19",
      "metadata": {
        "id": "NKOg11GyxB19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "758adc52-2d82-4785-9442-689fe2791aa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef agent_router(query):\\n    if any(op in query for op in [\"+\", \"-\", \"*\", \"/\", \"calculate\"]):\\n        tool = next(t for t in tools if \"Calculator\" in t.name)\\n        return tool.run(query)\\n    elif any(k in query.lower() for k in [\"who\", \"what\", \"where\", \"capital\", \"wiki\"]):\\n        tool = next(t for t in tools if \"Wikipedia\" in t.name)\\n        return tool.run(query)\\n    else:\\n        return llm.invoke(query)\\n\\nquestion = \"What is the capital of France\"\\nprint(agent_router(question))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#If versions werent downgraded , continue with this option\n",
        "'''\n",
        "def agent_router(query):\n",
        "    if any(op in query for op in [\"+\", \"-\", \"*\", \"/\", \"calculate\"]):\n",
        "        tool = next(t for t in tools if \"Calculator\" in t.name)\n",
        "        return tool.run(query)\n",
        "    elif any(k in query.lower() for k in [\"who\", \"what\", \"where\", \"capital\", \"wiki\"]):\n",
        "        tool = next(t for t in tools if \"Wikipedia\" in t.name)\n",
        "        return tool.run(query)\n",
        "    else:\n",
        "        return llm.invoke(query)\n",
        "\n",
        "question = \"What is the capital of France\"\n",
        "print(agent_router(question))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B9dciouDnlLJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B9dciouDnlLJ",
        "outputId": "6934a56b-416e-4560-91bc-21c0c35e1504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.14\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core==0.3.32\n",
            "  Downloading langchain_core-0.3.32-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-community==0.3.14\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai==0.2.14\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pydantic==2.9.2\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.14) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.14) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.14) (3.13.3)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.14)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.14)\n",
            "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.14) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.14) (2.32.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.14) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.32) (1.33)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core==0.3.32)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.32) (4.15.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.14) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.14) (0.4.3)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.14) (2.12.0)\n",
            "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai==0.2.14)\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.14) (0.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic==2.9.2)\n",
            "  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.32) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.14)\n",
            "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (4.67.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.14) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.14) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.14) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.14) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.14) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14) (1.1.0)\n",
            "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.32-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.4/412.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
            "Downloading langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydantic-core, packaging, pydantic, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.14.0\n",
            "    Uninstalling openai-2.14.0:\n",
            "      Successfully uninstalled openai-2.14.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.6.1\n",
            "    Uninstalling langsmith-0.6.1:\n",
            "      Successfully uninstalled langsmith-0.6.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.7\n",
            "    Uninstalling langchain-core-1.2.7:\n",
            "      Successfully uninstalled langchain-core-1.2.7\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 1.1.0\n",
            "    Uninstalling langchain-text-splitters-1.1.0:\n",
            "      Successfully uninstalled langchain-text-splitters-1.1.0\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 1.1.7\n",
            "    Uninstalling langchain-openai-1.1.7:\n",
            "      Successfully uninstalled langchain-openai-1.1.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.2.7\n",
            "    Uninstalling langchain-1.2.7:\n",
            "      Successfully uninstalled langchain-1.2.7\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.4.1\n",
            "    Uninstalling langchain-community-0.4.1:\n",
            "      Successfully uninstalled langchain-community-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-huggingface 1.2.0 requires langchain-core<2.0.0,>=1.2.0, but you have langchain-core 0.3.32 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.3.32 which is incompatible.\n",
            "langchain-classic 1.0.1 requires langchain-core<2.0.0,>=1.2.5, but you have langchain-core 0.3.32 which is incompatible.\n",
            "langchain-classic 1.0.1 requires langchain-text-splitters<2.0.0,>=1.1.0, but you have langchain-text-splitters 0.3.5 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "mcp 1.25.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.32 langchain-openai-0.2.14 langchain-text-splitters-0.3.5 langsmith-0.2.11 openai-1.109.1 packaging-24.2 pydantic-2.9.2 pydantic-core-2.23.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_community",
                  "langchain_core",
                  "langchain_openai",
                  "langsmith",
                  "openai",
                  "packaging",
                  "pydantic"
                ]
              },
              "id": "45c6b2ba61c54f89a6b19532f9e21bf6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Two options,\n",
        "#Downgrading & working with GPT model(older model say Gpt-4)\n",
        "'''\n",
        "!pip install -U \\\n",
        "  langchain==0.3.14 \\\n",
        "  langchain-core==0.3.32 \\\n",
        "  langchain-community==0.3.14 \\\n",
        "  langchain-openai==0.2.14 \\\n",
        "  pydantic==2.9.2\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0gSp9uR-n-kw",
      "metadata": {
        "id": "0gSp9uR-n-kw"
      },
      "outputs": [],
      "source": [
        "#If downgraded\n",
        "'''\n",
        "#After restarting session\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools\n",
        "import os\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IgaLBAqkIIhm",
      "metadata": {
        "id": "IgaLBAqkIIhm"
      },
      "outputs": [],
      "source": [
        "#If not downgraded and if correctly using GPT-5x models\n",
        "#Note** If using gpt model and AzureOpenAI or AzureChatOpenAI (refer: 'Working_with_AzureOpenAI' folder)\n",
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools as lc_load_tools\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"/content/.env\")\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    deployment_name=\"gpt-5.1-chat\",\n",
        "    api_version=\"2024-12-01-preview\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "splUu-JxpN_S",
      "metadata": {
        "id": "splUu-JxpN_S"
      },
      "outputs": [],
      "source": [
        "#from langchain_community.agent_toolkits.load_tools import load_tools as lc_load_tools\n",
        "tools = lc_load_tools([\"llm-math\", \"wikipedia\"], llm=llm)\n",
        "\n",
        "'''\n",
        "#works with older versions of langchain\n",
        "from langchain import hub\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        ")\n",
        "\n",
        "executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        ")\n",
        "\n",
        "executor.invoke(\n",
        "    {\"input\": \"What is the capital of France\"}\n",
        ")\n",
        "'''\n",
        "\n",
        "#Getting ur custom functions\n",
        "def get_tool_by_keyword(keyword):\n",
        "    for t in tools:\n",
        "        if keyword.lower() in t.name.lower():\n",
        "            return t\n",
        "    return None\n",
        "\n",
        "\n",
        "def agent(query: str):\n",
        "    q = query.lower()\n",
        "\n",
        "    # Math routing\n",
        "    if any(x in q for x in [\"*\", \"+\", \"-\", \"/\", \"calculate\", \"math\"]):\n",
        "        tool = get_tool_by_keyword(\"math\") or get_tool_by_keyword(\"calc\")\n",
        "        if tool:\n",
        "            return tool.run(query)\n",
        "\n",
        "    # Wikipedia routing\n",
        "    if any(x in q for x in [\"who\", \"what\", \"where\", \"capital\", \"wiki\"]):\n",
        "        tool = get_tool_by_keyword(\"wiki\")\n",
        "        if tool:\n",
        "            return tool.run(query)\n",
        "\n",
        "    # Fallback\n",
        "    return llm.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "idiSi1rSLbOg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "idiSi1rSLbOg",
        "outputId": "8f125c5d-7fdd-47a0-abec-bb468153399d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: List of capitals of France\\nSummary: This is a chronological list of capitals of France. The capital of France has been Paris since its liberation in 1944.\\n\\n\\n\\nPage: Capital punishment in France\\nSummary: Capital punishment in France (French: peine de mort en France) is banned by Article 66-1 of the Constitution of the French Republic, voted as a constitutional amendment by the Congress of the French Parliament on 19 February 2007 and simply stating \"No one can be sentenced to the death penalty\" (French: Nul ne peut être condamné à la peine de mort). The death penalty was already declared illegal on 9 October 1981 when President François Mitterrand signed a law prohibiting the judicial system from using it and commuting the sentences of the seven people on death row to life imprisonment. The last execution took place by guillotine, being the main legal method since the French Revolution; Hamida Djandoubi, a Tunisian citizen convicted of torture and murder on French soil, was put to death in September 1977 in Marseille.\\nMajor French death penalty abolitionists across time have included philosopher Voltaire; poet Victor Hugo; politicians Léon Gambetta, Jean Jaurès and Aristide Briand; and writers Alphonse de Lamartine and Albert Camus.\\n\\nPage: Capital city\\nSummary: A capital city, or just capital, is the municipality holding primary status in a country, state, province, department, or other subnational division, usually as its seat of government. A capital is typically a city that physically encompasses the government\\'s offices and meeting places; the status as capital is often designated by law or a constitution. In some jurisdictions, including several countries, different branches of government are in different settlements, sometimes meaning there are multiple official capitals. In some cases, a distinction is made between the official (constitutional) capital and the seat of government.\\nEnglish-language media often use the name of the capital metonymically to refer to the government sitting there. Thus, \"London–Washington relations\" is understood to mean diplomatic relations between the United Kingdom and the United States.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "agent(\"Capital of France?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kjPrARMHP0cz",
      "metadata": {
        "id": "kjPrARMHP0cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d332f82c-080b-4135-f671-72aa6f2b909e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The answer you are reading right now is generated by the **LLM (the AI model)**, not an external tool.\\n\\nIf a tool is used, I will always indicate it clearly.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 16, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5.1-chat-2025-11-13', 'system_fingerprint': None, 'id': 'chatcmpl-D1cviX5TUd4w6fpnORVwuqRUX25GP', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--019bf153-98d2-7f40-a06b-8fd14e5471bd-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 48, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "agent(\"Is it the tool or llm answering this question\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxKPoC2tUtcf"
      },
      "id": "rxKPoC2tUtcf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "3.0-Working_with_langchain_agents.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}